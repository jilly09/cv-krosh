{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2M99ENHn82o"
      },
      "outputs": [],
      "source": [
        "!export MODEL_NAME=\"CompVis/stable-diffusion-v1-4\"\n",
        "!export DATASET_NAME=\"lambdalabs/naruto-blip-captions\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jJ7NJJUpFcj",
        "outputId": "8ff82b6c-5401-4357-df7c-ea89fe095069"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'diffusers'...\n",
            "remote: Enumerating objects: 85462, done.\u001b[K\n",
            "remote: Counting objects: 100% (464/464), done.\u001b[K\n",
            "remote: Compressing objects: 100% (259/259), done.\u001b[K\n",
            "remote: Total 85462 (delta 351), reused 220 (delta 194), pack-reused 84998 (from 2)\u001b[K\n",
            "Receiving objects: 100% (85462/85462), 62.20 MiB | 22.53 MiB/s, done.\n",
            "Resolving deltas: 100% (62691/62691), done.\n",
            "Processing ./diffusers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.0.dev0) (8.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.0.dev0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.0.dev0) (0.29.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.0.dev0) (0.5.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.0.dev0) (11.1.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.33.0.dev0) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.33.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.33.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.33.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.33.0.dev0) (4.13.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers==0.33.0.dev0) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.33.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.33.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.33.0.dev0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.33.0.dev0) (2025.1.31)\n",
            "Building wheels for collected packages: diffusers\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.33.0.dev0-py3-none-any.whl size=3543094 sha256=037ebbdcf4bfb21a86900011249ebe51fb4534d1a0c37631c1667a7ba3e1d8f5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cc4w8_2y/wheels/30/15/ca/ab6e88c89d6ba7047b3f155894c6c346e7cf06067fd132ae62\n",
            "Successfully built diffusers\n",
            "Installing collected packages: diffusers\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.32.2\n",
            "    Uninstalling diffusers-0.32.2:\n",
            "      Successfully uninstalled diffusers-0.32.2\n",
            "Successfully installed diffusers-0.33.0.dev0\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/huggingface/diffusers\n",
        "!pip install diffusers/."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAYw0DoIqO7g",
        "outputId": "cc7da145-f302-4d3f-b0af-a3c5eb44fd64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate>=0.16.0 in /usr/local/lib/python3.11/dist-packages (from -r diffusers/examples/text_to_image/requirements.txt (line 1)) (1.5.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r diffusers/examples/text_to_image/requirements.txt (line 2)) (0.21.0+cu124)\n",
            "Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from -r diffusers/examples/text_to_image/requirements.txt (line 3)) (4.50.2)\n",
            "Collecting datasets>=2.19.1 (from -r diffusers/examples/text_to_image/requirements.txt (line 4))\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting ftfy (from -r diffusers/examples/text_to_image/requirements.txt (line 5))\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r diffusers/examples/text_to_image/requirements.txt (line 6)) (2.18.0)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.11/dist-packages (from -r diffusers/examples/text_to_image/requirements.txt (line 7)) (3.1.6)\n",
            "Collecting peft==0.7.0 (from -r diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Downloading peft-0.7.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (4.67.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (0.5.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (0.29.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->-r diffusers/examples/text_to_image/requirements.txt (line 2)) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.25.1->-r diffusers/examples/text_to_image/requirements.txt (line 3)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.25.1->-r diffusers/examples/text_to_image/requirements.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.25.1->-r diffusers/examples/text_to_image/requirements.txt (line 3)) (0.21.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (2.2.2)\n",
            "Collecting xxhash (from datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4))\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (3.11.14)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->-r diffusers/examples/text_to_image/requirements.txt (line 5)) (0.2.13)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2->-r diffusers/examples/text_to_image/requirements.txt (line 7)) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.25.1->-r diffusers/examples/text_to_image/requirements.txt (line 3)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.25.1->-r diffusers/examples/text_to_image/requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.25.1->-r diffusers/examples/text_to_image/requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.25.1->-r diffusers/examples/text_to_image/requirements.txt (line 3)) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (2025.2)\n",
            "Downloading peft-0.7.0-py3-none-any.whl (168 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, peft\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.14.0\n",
            "    Uninstalling peft-0.14.0:\n",
            "      Successfully uninstalled peft-0.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 ftfy-6.3.1 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 peft-0.7.0 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r diffusers/examples/text_to_image/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPWySnLdrBJH",
        "outputId": "bdacc9e1-2e90-4336-e0a8-dbe4cd90826a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r----------------------------------------------------------------------------------------------------In which compute environment are you running?\n",
            "Please input a choice index (starting from 0), and press enter\n",
            " ➔  \u001b[32mThis machine\u001b[0m\r\n",
            "    AWS (Amazon SageMaker)\r\n",
            "\u001b[2A\u001b[?25lTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/menu/cursor.py\", line 63, in hide\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/menu/selection_menu.py\", line 133, in run\n",
            "    choice = int(builtins.input())\n",
            "                 ^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/config/config.py\", line 67, in config_command\n",
            "    config = get_user_input()\n",
            "             ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/config/config.py\", line 32, in get_user_input\n",
            "    compute_environment = _ask_options(\n",
            "                          ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/config/config_utils.py\", line 63, in _ask_options\n",
            "    result = menu.run(default_choice=default)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/menu/selection_menu.py\", line 129, in run\n",
            "    with cursor.hide():\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 158, in __exit__\n",
            "    self.gen.throw(typ, value, traceback)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/menu/cursor.py\", line 65, in hide\n",
            "    show_cursor()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/menu/cursor.py\", line 54, in show_cursor\n",
            "    sys.stdout.write(\"\\033[?25h\")\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/console_capture.py\", line 146, in write_with_callbacks\n",
            "    def write_with_callbacks(s: AnyStr, /) -> int:\n",
            "\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!accelerate config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulHi0JRtsaW3"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL8rSZr9oCoK",
        "outputId": "8141a9e4-2231-4311-aa46-d8813ca66a49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-02 10:10:45.189709: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743588645.209986    5481 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743588645.216114    5481 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-02 10:10:45.236724: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "04/02/2025 10:10:48 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: no\n",
            "\n",
            "{'sample_max_value', 'thresholding', 'rescale_betas_zero_snr', 'timestep_spacing', 'prediction_type', 'variance_type', 'dynamic_thresholding_ratio', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
            "{'force_upcast', 'mid_block_add_attention', 'norm_num_groups', 'latents_std', 'shift_factor', 'use_quant_conv', 'latents_mean', 'use_post_quant_conv'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing AutoencoderKL.\n",
            "\n",
            "All the weights of AutoencoderKL were initialized from the model checkpoint at CompVis/stable-diffusion-v1-4.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.\n",
            "{'num_attention_heads', 'projection_class_embeddings_input_dim', 'resnet_out_scale_factor', 'addition_embed_type_num_heads', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'conv_out_kernel', 'time_embedding_dim', 'encoder_hid_dim_type', 'time_embedding_act_fn', 'encoder_hid_dim', 'dropout', 'attention_type', 'time_cond_proj_dim', 'addition_embed_type', 'class_embed_type', 'num_class_embeds', 'resnet_skip_time_act', 'cross_attention_norm', 'addition_time_embed_dim', 'only_cross_attention', 'conv_in_kernel', 'use_linear_projection', 'transformer_layers_per_block', 'upcast_attention', 'dual_cross_attention', 'time_embedding_type', 'mid_block_type', 'reverse_transformer_layers_per_block', 'resnet_time_scale_shift', 'timestep_post_act'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing UNet2DConditionModel.\n",
            "\n",
            "All the weights of UNet2DConditionModel were initialized from the model checkpoint at CompVis/stable-diffusion-v1-4.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use UNet2DConditionModel for predictions without further training.\n",
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "04/02/2025 10:10:55 - WARNING - huggingface_hub.repocard - Repo card metadata block was not found. Setting CardData to empty.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "04/02/2025 10:11:05 - INFO - __main__ - ***** Running training *****\n",
            "04/02/2025 10:11:05 - INFO - __main__ -   Num examples = 1221\n",
            "04/02/2025 10:11:05 - INFO - __main__ -   Num Epochs = 100\n",
            "04/02/2025 10:11:05 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
            "04/02/2025 10:11:05 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "04/02/2025 10:11:05 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "04/02/2025 10:11:05 - INFO - __main__ -   Total optimization steps = 122100\n",
            "Steps:   0% 83/122100 [01:22<33:45:40,  1.00it/s, lr=0.0001, step_loss=0.033] Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/subprocess.py\", line 1264, in wait\n",
            "    return self._wait(timeout=timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/subprocess.py\", line 2053, in _wait\n",
            "    (pid, sts) = self._try_wait(0)\n",
            "                 ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/subprocess.py\", line 2011, in _try_wait\n",
            "    (pid, sts) = os.waitpid(self.pid, wait_flags)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 1194, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 777, in simple_launcher\n",
            "    process.wait()\n",
            "  File \"/usr/lib/python3.11/subprocess.py\", line 1277, in wait\n",
            "    self._wait(timeout=sigint_timeout)\n",
            "  File \"/usr/lib/python3.11/subprocess.py\", line 2047, in _wait\n",
            "    time.sleep(delay)\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/diffusers/examples/text_to_image/train_text_to_image_lora.py\", line 975, in <module>\n",
            "    main()\n",
            "  File \"/content/diffusers/examples/text_to_image/train_text_to_image_lora.py\", line 850, in main\n",
            "    train_loss += avg_loss.item() / args.gradient_accumulation_steps\n",
            "                  ^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/wandb/offline-run-20250402_101105-xz8hz6yc\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20250402_101105-xz8hz6yc/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!accelerate launch --mixed_precision=\"no\" diffusers/examples/text_to_image/train_text_to_image_lora.py \\\n",
        "  --pretrained_model_name_or_path=\"CompVis/stable-diffusion-v1-4\" \\\n",
        "  --dataset_name=\"lambdalabs/naruto-blip-captions\" --caption_column=\"text\" \\\n",
        "  --resolution=512 --random_flip \\\n",
        "  --train_batch_size=1 \\\n",
        "  --num_train_epochs=100 --checkpointing_steps=5000 \\\n",
        "  --learning_rate=1e-04 --lr_scheduler=\"constant\" --lr_warmup_steps=0 \\\n",
        "  --seed=42 \\\n",
        "  --output_dir=\"sd-naruto-model-lora\" \\\n",
        "  --validation_prompt=\"cute dragon creature\" --report_to=\"wandb\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPCDKt7IEqZP",
        "outputId": "afd57e7d-8afe-4cba-d79d-a24ed7987795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-02 16:21:28.517026: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743610888.826148    3153 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743610888.905310    3153 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-02 16:21:29.551323: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "04/02/2025 16:21:36 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: no\n",
            "\n",
            "scheduler_config.json: 100% 313/313 [00:00<00:00, 2.04MB/s]\n",
            "{'rescale_betas_zero_snr', 'thresholding', 'dynamic_thresholding_ratio', 'variance_type', 'clip_sample_range', 'prediction_type', 'timestep_spacing', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "tokenizer_config.json: 100% 806/806 [00:00<00:00, 5.52MB/s]\n",
            "vocab.json: 100% 1.06M/1.06M [00:00<00:00, 12.6MB/s]\n",
            "merges.txt: 100% 525k/525k [00:00<00:00, 9.77MB/s]\n",
            "special_tokens_map.json: 100% 472/472 [00:00<00:00, 4.09MB/s]\n",
            "config.json: 100% 592/592 [00:00<00:00, 300kB/s]\n",
            "model.safetensors: 100% 492M/492M [00:05<00:00, 94.7MB/s]\n",
            "config.json: 100% 551/551 [00:00<00:00, 4.61MB/s]\n",
            "diffusion_pytorch_model.safetensors: 100% 335M/335M [00:02<00:00, 140MB/s]\n",
            "{'mid_block_add_attention', 'use_post_quant_conv', 'force_upcast', 'latents_mean', 'latents_std', 'shift_factor', 'use_quant_conv', 'norm_num_groups'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing AutoencoderKL.\n",
            "\n",
            "All the weights of AutoencoderKL were initialized from the model checkpoint at CompVis/stable-diffusion-v1-4.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.\n",
            "config.json: 100% 743/743 [00:00<00:00, 6.30MB/s]\n",
            "diffusion_pytorch_model.safetensors: 100% 3.44G/3.44G [00:30<00:00, 112MB/s]\n",
            "{'encoder_hid_dim', 'transformer_layers_per_block', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'conv_out_kernel', 'resnet_skip_time_act', 'timestep_post_act', 'projection_class_embeddings_input_dim', 'addition_time_embed_dim', 'dropout', 'num_class_embeds', 'attention_type', 'only_cross_attention', 'dual_cross_attention', 'upcast_attention', 'time_embedding_dim', 'mid_block_only_cross_attention', 'mid_block_type', 'time_embedding_type', 'num_attention_heads', 'cross_attention_norm', 'resnet_time_scale_shift', 'conv_in_kernel', 'addition_embed_type', 'addition_embed_type_num_heads', 'class_embed_type', 'class_embeddings_concat', 'reverse_transformer_layers_per_block', 'encoder_hid_dim_type', 'use_linear_projection', 'time_embedding_act_fn'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing UNet2DConditionModel.\n",
            "\n",
            "All the weights of UNet2DConditionModel were initialized from the model checkpoint at CompVis/stable-diffusion-v1-4.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use UNet2DConditionModel for predictions without further training.\n",
            "Resolving data files: 100% 101/101 [00:00<00:00, 394436.41it/s]\n",
            "Downloading data: 100% 98/98 [00:00<00:00, 43131.35files/s]\n",
            "Generating train split: 97 examples [00:00, 2327.12 examples/s]\n",
            "04/02/2025 16:22:24 - INFO - __main__ - ***** Running training *****\n",
            "04/02/2025 16:22:24 - INFO - __main__ -   Num examples = 97\n",
            "04/02/2025 16:22:24 - INFO - __main__ -   Num Epochs = 100\n",
            "04/02/2025 16:22:24 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
            "04/02/2025 16:22:24 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "04/02/2025 16:22:24 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "04/02/2025 16:22:24 - INFO - __main__ -   Total optimization steps = 9700\n",
            "Steps:  52% 5000/9700 [1:26:09<1:21:00,  1.03s/it, lr=0.0001, step_loss=0.0183]04/02/2025 17:48:34 - INFO - accelerate.accelerator - Saving current state to mymodel/checkpoint-5000\n",
            "04/02/2025 17:48:58 - INFO - accelerate.checkpointing - Model weights saved in mymodel/checkpoint-5000/model.safetensors\n",
            "04/02/2025 17:48:58 - INFO - accelerate.checkpointing - Optimizer state saved in mymodel/checkpoint-5000/optimizer.bin\n",
            "04/02/2025 17:48:58 - INFO - accelerate.checkpointing - Scheduler state saved in mymodel/checkpoint-5000/scheduler.bin\n",
            "04/02/2025 17:48:58 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in mymodel/checkpoint-5000/sampler.bin\n",
            "04/02/2025 17:48:58 - INFO - accelerate.checkpointing - Random states saved in mymodel/checkpoint-5000/random_states_0.pkl\n",
            "Model weights saved in mymodel/checkpoint-5000/pytorch_lora_weights.safetensors\n",
            "04/02/2025 17:48:58 - INFO - __main__ - Saved state to mymodel/checkpoint-5000\n",
            "Steps: 100% 9700/9700 [2:47:36<00:00,  1.03s/it, lr=0.0001, step_loss=0.00358]Model weights saved in mymodel/pytorch_lora_weights.safetensors\n",
            "Steps: 100% 9700/9700 [2:47:36<00:00,  1.04s/it, lr=0.0001, step_loss=0.00358]\n"
          ]
        }
      ],
      "source": [
        "!accelerate launch --mixed_precision=\"no\" diffusers/examples/text_to_image/train_text_to_image_lora.py \\\n",
        "  --pretrained_model_name_or_path=\"CompVis/stable-diffusion-v1-4\" \\\n",
        "  --train_data_dir=\"drive/MyDrive/dataset\" \\\n",
        "  --resolution=512 --random_flip \\\n",
        "  --train_batch_size=1 \\\n",
        "  --num_train_epochs=100 --checkpointing_steps=5000 \\\n",
        "  --learning_rate=1e-04 --lr_scheduler=\"constant\" --lr_warmup_steps=0 \\\n",
        "  --seed=42 \\\n",
        "  --output_dir=\"mymodel\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}